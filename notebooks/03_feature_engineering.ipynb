{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Feature Engineering (Evidence-Based)\n",
    "\n",
    "## Objective\n",
    "Engineer **38 effective features** based on EDA findings from Notebook 02.\n",
    "\n",
    "## Key Insights from Exploration (Notebook 02):\n",
    "\n",
    "### What Matters (High Correlation):\n",
    "- **Player rolling averages** (PTS/REB/AST last 3/5/10 games) - captures recent form\n",
    "- **Season averages** - baseline performance level\n",
    "- **Opponent defensive rating** - +9% effect (Elite D: 12.66 PTS vs Weak D: 13.82 PTS)\n",
    "- **IS_HOME** - consistent +1.7% boost\n",
    "- **Player shot tendencies** - archetype matters (rim runner vs shooter)\n",
    "\n",
    "### What Doesn't Matter (Low Correlation):\n",
    "- **TEAM_PACE** - r=0.014, only +2.4% effect (keep but don't expect much)\n",
    "- **IS_B2B** - paradox: +1.7% scoring (no fatigue signal) ‚Üí **EXCLUDE**\n",
    "- **Hot hand binary** - selection bias artifact ‚Üí Use continuous momentum instead\n",
    "\n",
    "### The Fundamental Challenge:\n",
    "- FGA (r=0.874) and MIN (r=0.683) are strongest predictors but **unavailable at prediction time**\n",
    "- This creates a performance ceiling - we must predict without knowing usage\n",
    "\n",
    "## Features (38 total):\n",
    "\n",
    "1. **Rolling Averages (9)**: PTS/REB/AST last 3, 5, 10 games\n",
    "2. **Season Context (6)**: Season avg PTS/REB/AST, SEASON_GAME_NUM, month, day_of_week\n",
    "3. **Opponent Context (4)**: OPP_DEF_RATING, OPP_PACE, OPP_W_PCT, OPP_OFF_RATING\n",
    "4. **Team Context (4)**: TEAM_DEF_RATING, TEAM_PACE, TEAM_W_PCT, TEAM_OFF_RATING\n",
    "5. **Game Context (5)**: IS_HOME, DAYS_REST, REST_0_1, REST_2_3, REST_4_PLUS\n",
    "6. **Shot Tendencies (4)**: Season % from: Restricted Area, Paint, Mid-Range, Three-Point\n",
    "7. **Momentum (6)**: PTS/REB/AST trends (last 5 games slope) + volatility (std)\n",
    "\n",
    "## Data Quality:\n",
    "- **Leakage prevention**: All features use `.shift(1)` before rolling operations\n",
    "- **Shot tendencies**: Season averages only (not per-game, as data doesn't exist pre-game)\n",
    "- **Rest days**: Binned for non-linear effects (4+ days = injury signal)\n",
    "\n",
    "## Train/Val/Test Split:\n",
    "- **Temporal split** (not random!)\n",
    "- Train: < 2023-01-01 (~70%)\n",
    "- Val: 2023-01-01 to 2024-01-01 (~15%)\n",
    "- Test: >= 2024-01-01 (~15%)\n",
    "\n",
    "## Output:\n",
    "- `data/processed/features_engineered.parquet` - Full dataset with 38 features\n",
    "- `data/processed/train.parquet` - Training set\n",
    "- `data/processed/val.parquet` - Validation set\n",
    "- `data/processed/test.parquet` - Test set\n",
    "- `data/processed/feature_metadata_v2.json` - Feature documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load PROCESSED Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"‚úÖ Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 72,509 games from 289 players\n",
      "Date range: 2019-10-22 to 2024-04-14\n",
      "\n",
      "Columns: 45\n",
      "Sample opponent/team features: ['OPP_TEAM_ABBREV', 'OPP_TEAM_NAME', 'OPP_DEF_RATING', 'OPP_OFF_RATING', 'OPP_PACE', 'OPP_W', 'OPP_L', 'OPP_W_PCT']\n"
     ]
    }
   ],
   "source": [
    "# Load PROCESSED game logs (cleaned, deduplicated, with opponent/team context)\n",
    "df = pd.read_parquet('../data/processed/gamelogs_combined.parquet')\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "df = df.sort_values(['PLAYER_ID', 'GAME_DATE']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df):,} games from {df['PLAYER_ID'].nunique()} players\")\n",
    "print(f\"Date range: {df['GAME_DATE'].min().date()} to {df['GAME_DATE'].max().date()}\")\n",
    "print(f\"\\nColumns: {df.shape[1]}\")\n",
    "print(f\"Sample opponent/team features: {[c for c in df.columns if 'OPP_' in c or 'TEAM_' in c][:8]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rolling Averages (9 features)\n",
    "\n",
    "Recent performance for targets only (not FGA/FTA/TOV - those won't exist at prediction time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rolling averages (leakage-safe with .shift(1))...\n",
      "\n",
      "‚úÖ 9 rolling features created (PTS/REB/AST √ó 3/5/10 games)\n",
      "   Sample: PTS_LAST_3 range = 0.0 to 52.7\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating rolling averages (leakage-safe with .shift(1))...\\n\")\n",
    "\n",
    "# Only for target variables (PTS/REB/AST)\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    for window in [3, 5, 10]:\n",
    "        df[f'{stat}_LAST_{window}'] = (\n",
    "            df.groupby('PLAYER_ID')[stat]\n",
    "            .shift(1)  # CRITICAL: Don't include current game\n",
    "            .rolling(window, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ 9 rolling features created (PTS/REB/AST √ó 3/5/10 games)\")\n",
    "print(f\"   Sample: PTS_LAST_3 range = {df['PTS_LAST_3'].min():.1f} to {df['PTS_LAST_3'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Season Context (6 features)\n",
    "\n",
    "Season averages, game count, timing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating season context features...\n",
      "\n",
      "‚úÖ 6 season context features created\n",
      "   SEASON_GAME_NUM range: 1 to 84\n",
      "   MONTH range: 1 to 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating season context features...\\n\")\n",
    "\n",
    "# Season averages (expanding mean, leakage-safe)\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    df[f'{stat}_SEASON_AVG'] = (\n",
    "        df.groupby(['PLAYER_ID', 'SEASON'])[stat]\n",
    "        .apply(lambda x: x.shift(1).expanding().mean())\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "# Games played this season (so far)\n",
    "df['SEASON_GAME_NUM'] = df.groupby(['PLAYER_ID', 'SEASON']).cumcount() + 1\n",
    "\n",
    "# Month (October = 10, April = 4)\n",
    "df['MONTH'] = df['GAME_DATE'].dt.month\n",
    "\n",
    "# Day of week (0=Monday, 6=Sunday)\n",
    "df['DAY_OF_WEEK'] = df['GAME_DATE'].dt.dayofweek\n",
    "\n",
    "print(\"‚úÖ 6 season context features created\")\n",
    "print(f\"   SEASON_GAME_NUM range: {df['SEASON_GAME_NUM'].min()} to {df['SEASON_GAME_NUM'].max()}\")\n",
    "print(f\"   MONTH range: {df['MONTH'].min()} to {df['MONTH'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Opponent Context (4 features)\n",
    "\n",
    "From EDA: OPP_DEF_RATING has +9% effect (Elite D: 12.66 vs Weak D: 13.82 PTS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opponent context features...\n",
      "\n",
      "‚úÖ 4 opponent context features confirmed\n",
      "   OPP_DEF_RATING range: 102.5 to 119.6\n",
      "   OPP_PACE range: 95.6 to 105.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Opponent context features...\\n\")\n",
    "\n",
    "# These columns already exist in processed data from 01_data_collection\n",
    "opponent_features = ['OPP_DEF_RATING', 'OPP_PACE', 'OPP_W_PCT', 'OPP_OFF_RATING']\n",
    "\n",
    "# Verify they exist\n",
    "missing = [c for c in opponent_features if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è  Missing opponent features: {missing}\")\n",
    "else:\n",
    "    print(f\"‚úÖ 4 opponent context features confirmed\")\n",
    "    print(f\"   OPP_DEF_RATING range: {df['OPP_DEF_RATING'].min():.1f} to {df['OPP_DEF_RATING'].max():.1f}\")\n",
    "    print(f\"   OPP_PACE range: {df['OPP_PACE'].min():.1f} to {df['OPP_PACE'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Team Context (4 features)\n",
    "\n",
    "From EDA: TEAM_PACE has minimal effect (r=0.014, +2.4%), but keep for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team context features...\n",
      "\n",
      "‚úÖ 4 team context features confirmed\n",
      "   TEAM_PACE range: 95.6 to 105.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Team context features...\\n\")\n",
    "\n",
    "# These columns already exist in processed data from 01_data_collection\n",
    "team_features = ['TEAM_DEF_RATING', 'TEAM_PACE', 'TEAM_W_PCT', 'TEAM_OFF_RATING']\n",
    "\n",
    "# Verify they exist\n",
    "missing = [c for c in team_features if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è  Missing team features: {missing}\")\n",
    "else:\n",
    "    print(f\"‚úÖ 4 team context features confirmed\")\n",
    "    print(f\"   TEAM_PACE range: {df['TEAM_PACE'].min():.1f} to {df['TEAM_PACE'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Game Context (5 features)\n",
    "\n",
    "From EDA: \n",
    "- IS_HOME has consistent +1.7% boost\n",
    "- DAYS_REST has non-linear effect (4+ days = injury signal, lower scoring)\n",
    "- **Excluding IS_B2B** (paradoxically +1.7% scoring, no fatigue effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating game context features...\n",
      "\n",
      "‚úÖ 5 game context features created\n",
      "   IS_HOME: 50.1% home games\n",
      "   REST_0_1: 15.8%\n",
      "   REST_2_3: 72.9%\n",
      "   REST_4_PLUS: 11.3%\n",
      "\n",
      "   NOTE: IS_B2B excluded (EDA showed +1.7% paradox, no fatigue effect)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating game context features...\\n\")\n",
    "\n",
    "# Home/away indicator (already exists in processed data as IS_HOME)\n",
    "if 'IS_HOME' not in df.columns:\n",
    "    df['IS_HOME'] = df['MATCHUP'].apply(lambda x: 1 if 'vs.' in x else 0)\n",
    "\n",
    "# DAYS_REST already exists in processed data\n",
    "# Create binned versions for non-linear relationship\n",
    "df['REST_0_1'] = (df['DAYS_REST'] <= 1).astype(int)  # 0-1 days\n",
    "df['REST_2_3'] = ((df['DAYS_REST'] >= 2) & (df['DAYS_REST'] <= 3)).astype(int)  # 2-3 days\n",
    "df['REST_4_PLUS'] = (df['DAYS_REST'] >= 4).astype(int)  # 4+ days (injury signal)\n",
    "\n",
    "print(\"‚úÖ 5 game context features created\")\n",
    "print(f\"   IS_HOME: {df['IS_HOME'].mean()*100:.1f}% home games\")\n",
    "print(f\"   REST_0_1: {df['REST_0_1'].mean()*100:.1f}%\")\n",
    "print(f\"   REST_2_3: {df['REST_2_3'].mean()*100:.1f}%\")\n",
    "print(f\"   REST_4_PLUS: {df['REST_4_PLUS'].mean()*100:.1f}%\")\n",
    "print(f\"\\n   NOTE: IS_B2B excluded (EDA showed +1.7% paradox, no fatigue effect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Shot Tendencies (4 features)\n",
    "\n",
    "**CRITICAL**: Shot data doesn't exist pre-game, so we use **season averages** (not per-game).\n",
    "\n",
    "Calculate % of shots from each zone using player's prior games in the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shot chart data...\\n\n",
      "Loaded 591,467 shots from 229 players\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading shot chart data...\\\\n\")\n",
    "\n",
    "df_shots = pd.read_parquet('../data/processed/shot_charts_all.parquet')\n",
    "df_shots['GAME_DATE'] = pd.to_datetime(df_shots['GAME_DATE'])\n",
    "\n",
    "# Rename 'Season' to 'SEASON' for consistency\\n\n",
    "if 'Season' in df_shots.columns:\n",
    "    df_shots.rename(columns={'Season': 'SEASON'}, inplace=True)\n",
    "\n",
    "print(f\"Loaded {len(df_shots):,} shots from {df_shots['PLAYER_ID'].nunique()} players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating season-to-date shot tendencies...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Players: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 974/974 [00:11<00:00, 84.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Shot tendencies calculated for 55,949 player-games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating season-to-date shot tendencies...\\n\")\n",
    "\n",
    "# Map zones to simplified categories\n",
    "def map_zone(z):\n",
    "    if z == 'Restricted Area': return 'RESTRICTED_AREA'\n",
    "    if z == 'In The Paint (Non-RA)': return 'PAINT'\n",
    "    if z == 'Mid-Range': return 'MIDRANGE'\n",
    "    if z in ['Above the Break 3', 'Left Corner 3', 'Right Corner 3']: return 'THREE_PT'\n",
    "    return 'OTHER'\n",
    "\n",
    "df_shots['ZONE'] = df_shots['SHOT_ZONE_BASIC'].apply(map_zone)\n",
    "\n",
    "# For each player-game, calculate zone percentages from PRIOR games in season\n",
    "shot_tendencies_list = []\n",
    "\n",
    "for (player, season), group in tqdm(df_shots.groupby(['PLAYER_ID', 'SEASON']), desc=\"Players\"):\n",
    "    group = group.sort_values('GAME_DATE')\n",
    "    game_dates = group['GAME_DATE'].unique()\n",
    "    \n",
    "    for game_date in game_dates:\n",
    "        # Get all PRIOR games in this season\n",
    "        prior_shots = group[group['GAME_DATE'] < game_date]\n",
    "        \n",
    "        if len(prior_shots) == 0:\n",
    "            # No prior games - use league averages or zeros\n",
    "            shot_tendencies_list.append({\n",
    "                'PLAYER_ID': player,\n",
    "                'GAME_DATE': game_date,\n",
    "                'SEASON': season,\n",
    "                'RESTRICTED_AREA_PCT': 0.25,  # Reasonable defaults\n",
    "                'PAINT_PCT': 0.15,\n",
    "                'MIDRANGE_PCT': 0.20,\n",
    "                'THREE_PT_PCT': 0.40\n",
    "            })\n",
    "        else:\n",
    "            # Calculate zone percentages from prior games\n",
    "            zone_counts = prior_shots['ZONE'].value_counts()\n",
    "            total_shots = len(prior_shots)\n",
    "            \n",
    "            shot_tendencies_list.append({\n",
    "                'PLAYER_ID': player,\n",
    "                'GAME_DATE': game_date,\n",
    "                'SEASON': season,\n",
    "                'RESTRICTED_AREA_PCT': zone_counts.get('RESTRICTED_AREA', 0) / total_shots,\n",
    "                'PAINT_PCT': zone_counts.get('PAINT', 0) / total_shots,\n",
    "                'MIDRANGE_PCT': zone_counts.get('MIDRANGE', 0) / total_shots,\n",
    "                'THREE_PT_PCT': zone_counts.get('THREE_PT', 0) / total_shots\n",
    "            })\n",
    "\n",
    "df_shot_tendencies = pd.DataFrame(shot_tendencies_list)\n",
    "\n",
    "print(f\"\\n‚úÖ Shot tendencies calculated for {len(df_shot_tendencies):,} player-games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging shot tendencies with game logs...\n",
      "\n",
      "‚úÖ 4 shot tendency features added\n",
      "   Missing shot data: 0.0%\n",
      "   Sample distributions:\n",
      "      RESTRICTED_AREA_PCT: 29.1%\n",
      "      PAINT_PCT: 16.5%\n",
      "      MIDRANGE_PCT: 13.9%\n",
      "      THREE_PT_PCT: 40.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging shot tendencies with game logs...\\n\")\n",
    "\n",
    "# Merge with main dataframe\n",
    "df = df.merge(\n",
    "    df_shot_tendencies,\n",
    "    on=['PLAYER_ID', 'GAME_DATE', 'SEASON'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values (players with no shot data) with league averages\n",
    "df['RESTRICTED_AREA_PCT'] = df['RESTRICTED_AREA_PCT'].fillna(0.25)\n",
    "df['PAINT_PCT'] = df['PAINT_PCT'].fillna(0.15)\n",
    "df['MIDRANGE_PCT'] = df['MIDRANGE_PCT'].fillna(0.20)\n",
    "df['THREE_PT_PCT'] = df['THREE_PT_PCT'].fillna(0.40)\n",
    "\n",
    "print(\"‚úÖ 4 shot tendency features added\")\n",
    "print(f\"   Missing shot data: {df[['RESTRICTED_AREA_PCT', 'PAINT_PCT']].isnull().mean().mean()*100:.1f}%\")\n",
    "print(f\"   Sample distributions:\")\n",
    "print(f\"      RESTRICTED_AREA_PCT: {df['RESTRICTED_AREA_PCT'].mean()*100:.1f}%\")\n",
    "print(f\"      PAINT_PCT: {df['PAINT_PCT'].mean()*100:.1f}%\")\n",
    "print(f\"      MIDRANGE_PCT: {df['MIDRANGE_PCT'].mean()*100:.1f}%\")\n",
    "print(f\"      THREE_PT_PCT: {df['THREE_PT_PCT'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Momentum (6 features)\n",
    "\n",
    "Trends (slope) and volatility (std) for recent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating momentum features...\n",
      "\n",
      "‚úÖ 6 momentum features created (3 trends + 3 volatility)\n",
      "   PTS_TREND range: -10.90 to 11.80\n",
      "   PTS_VOLATILITY range: 0.00 to 24.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating momentum features...\\n\")\n",
    "\n",
    "def calculate_trend(series):\n",
    "    \"\"\"Calculate linear trend (slope) of series\"\"\"\n",
    "    if len(series) < 2:\n",
    "        return 0\n",
    "    return np.polyfit(np.arange(len(series)), series, 1)[0]\n",
    "\n",
    "# Trend (slope) for target stats over last 5 games\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    df[f'{stat}_TREND'] = (\n",
    "        df.groupby('PLAYER_ID')[stat]\n",
    "        .shift(1)\n",
    "        .rolling(5, min_periods=2)\n",
    "        .apply(calculate_trend, raw=True)\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "# Volatility (std) for target stats over last 5 games\n",
    "for stat in ['PTS', 'REB', 'AST']:\n",
    "    df[f'{stat}_VOLATILITY'] = (\n",
    "        df.groupby('PLAYER_ID')[stat]\n",
    "        .shift(1)\n",
    "        .rolling(5, min_periods=2)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ 6 momentum features created (3 trends + 3 volatility)\")\n",
    "print(f\"   PTS_TREND range: {df['PTS_TREND'].min():.2f} to {df['PTS_TREND'].max():.2f}\")\n",
    "print(f\"   PTS_VOLATILITY range: {df['PTS_VOLATILITY'].min():.2f} to {df['PTS_VOLATILITY'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Finalize Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining final feature set...\n",
      "\n",
      "‚úÖ Final feature set prepared\n",
      "\n",
      "   Total games: 68,765\n",
      "   Total features: 38\n",
      "\n",
      "   Feature breakdown:\n",
      "      Rolling averages:    9\n",
      "      Season context:      6\n",
      "      Opponent context:    4\n",
      "      Team context:        4\n",
      "      Game context:        5\n",
      "      Shot tendencies:     4\n",
      "      Momentum:            6\n",
      "      ----------------------\n",
      "      TOTAL:              38 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining final feature set...\\n\")\n",
    "\n",
    "# Feature columns (~40 total)\n",
    "feature_columns = [\n",
    "    # ========== ROLLING AVERAGES (9) ==========\n",
    "    'PTS_LAST_3', 'PTS_LAST_5', 'PTS_LAST_10',\n",
    "    'REB_LAST_3', 'REB_LAST_5', 'REB_LAST_10',\n",
    "    'AST_LAST_3', 'AST_LAST_5', 'AST_LAST_10',\n",
    "    \n",
    "    # ========== SEASON CONTEXT (6) ==========\n",
    "    'PTS_SEASON_AVG', 'REB_SEASON_AVG', 'AST_SEASON_AVG',\n",
    "    'SEASON_GAME_NUM', 'MONTH', 'DAY_OF_WEEK',\n",
    "    \n",
    "    # ========== OPPONENT CONTEXT (4) ==========\n",
    "    'OPP_DEF_RATING', 'OPP_PACE', 'OPP_W_PCT', 'OPP_OFF_RATING',\n",
    "    \n",
    "    # ========== TEAM CONTEXT (4) ==========\n",
    "    'TEAM_DEF_RATING', 'TEAM_PACE', 'TEAM_W_PCT', 'TEAM_OFF_RATING',\n",
    "    \n",
    "    # ========== GAME CONTEXT (5) ==========\n",
    "    'IS_HOME', 'DAYS_REST', 'REST_0_1', 'REST_2_3', 'REST_4_PLUS',\n",
    "    \n",
    "    # ========== SHOT TENDENCIES (4) ==========\n",
    "    'RESTRICTED_AREA_PCT', 'PAINT_PCT', 'MIDRANGE_PCT', 'THREE_PT_PCT',\n",
    "    \n",
    "    # ========== MOMENTUM (6) ==========\n",
    "    'PTS_TREND', 'REB_TREND', 'AST_TREND',\n",
    "    'PTS_VOLATILITY', 'REB_VOLATILITY', 'AST_VOLATILITY'\n",
    "]\n",
    "\n",
    "# Tracking columns\n",
    "tracking = ['PLAYER_ID', 'PLAYER_NAME', 'GAME_ID', 'GAME_DATE', 'SEASON', 'MATCHUP']\n",
    "\n",
    "# Target columns\n",
    "targets = ['PTS', 'REB', 'AST']\n",
    "\n",
    "# Filter to games with sufficient history (at least 3 games played)\n",
    "df_filtered = df[df['SEASON_GAME_NUM'] >= 4].copy()\n",
    "\n",
    "# Select final columns\n",
    "df_final = df_filtered[tracking + feature_columns + targets].copy()\n",
    "\n",
    "print(f\"‚úÖ Final feature set prepared\\n\")\n",
    "print(f\"   Total games: {len(df_final):,}\")\n",
    "print(f\"   Total features: {len(feature_columns)}\\n\")\n",
    "print(f\"   Feature breakdown:\")\n",
    "print(f\"      Rolling averages:    9\")\n",
    "print(f\"      Season context:      6\")\n",
    "print(f\"      Opponent context:    4\")\n",
    "print(f\"      Team context:        4\")\n",
    "print(f\"      Game context:        5\")\n",
    "print(f\"      Shot tendencies:     4\")\n",
    "print(f\"      Momentum:            6\")\n",
    "print(f\"      ----------------------\")\n",
    "print(f\"      TOTAL:              {len(feature_columns)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train/Val/Test Split (Temporal)\n",
    "\n",
    "**CRITICAL**: Use temporal split (not random) to prevent leakage.\n",
    "\n",
    "- **Train**: < 2023-01-01 (~70%)\n",
    "- **Val**: 2023-01-01 to 2024-01-01 (~15%)\n",
    "- **Test**: >= 2024-01-01 (~15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal train/val/test split...\n",
      "\n",
      "‚úÖ Temporal split complete\n",
      "\n",
      "   Train: 46,824 games (68.1%) | 2019-10-28 to 2022-12-31\n",
      "   Val:   13,337 games (19.4%) | 2023-01-01 to 2023-12-31\n",
      "   Test:  8,604 games (12.5%) | 2024-01-01 to 2024-04-14\n",
      "\n",
      "   Total: 68,765 games\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating temporal train/val/test split...\\n\")\n",
    "\n",
    "# Define split dates\n",
    "train_end = pd.Timestamp('2023-01-01')\n",
    "val_end = pd.Timestamp('2024-01-01')\n",
    "\n",
    "# Create masks\n",
    "train_mask = df_final['GAME_DATE'] < train_end\n",
    "val_mask = (df_final['GAME_DATE'] >= train_end) & (df_final['GAME_DATE'] < val_end)\n",
    "test_mask = df_final['GAME_DATE'] >= val_end\n",
    "\n",
    "# Split datasets\n",
    "train = df_final[train_mask].copy()\n",
    "val = df_final[val_mask].copy()\n",
    "test = df_final[test_mask].copy()\n",
    "\n",
    "print(\"‚úÖ Temporal split complete\\n\")\n",
    "print(f\"   Train: {len(train):,} games ({len(train)/len(df_final)*100:.1f}%) | {train['GAME_DATE'].min().date()} to {train['GAME_DATE'].max().date()}\")\n",
    "print(f\"   Val:   {len(val):,} games ({len(val)/len(df_final)*100:.1f}%) | {val['GAME_DATE'].min().date()} to {val['GAME_DATE'].max().date()}\")\n",
    "print(f\"   Test:  {len(test):,} games ({len(test)/len(df_final)*100:.1f}%) | {test['GAME_DATE'].min().date()} to {test['GAME_DATE'].max().date()}\")\n",
    "print(f\"\\n   Total: {len(df_final):,} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Datasets & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving datasets and metadata...\n",
      "\n",
      "======================================================================\n",
      "‚úÖ FEATURE ENGINEERING COMPLETE (EVIDENCE-BASED)\n",
      "======================================================================\n",
      "\n",
      "Files saved:\n",
      "  üìä data/processed/features_engineered.parquet (68,765 games)\n",
      "  üìä data/processed/train.parquet (46,824 games)\n",
      "  üìä data/processed/val.parquet (13,337 games)\n",
      "  üìä data/processed/test.parquet (8,604 games)\n",
      "  üìã data/processed/feature_metadata_v2.json\n",
      "\n",
      "Key improvements from v1.0:\n",
      "  ‚úÖ Reduced from 81 to 38 evidence-based features\n",
      "  ‚úÖ Excluded IS_B2B (no fatigue effect)\n",
      "  ‚úÖ Shot tendencies as season averages (not per-game)\n",
      "  ‚úÖ Binned DAYS_REST for non-linear effects\n",
      "  ‚úÖ Added opponent/team context from processed data\n",
      "  ‚úÖ Temporal train/val/test split (prevents leakage)\n",
      "\n",
      "Next step: Notebook 04 for baseline model training!\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving datasets and metadata...\\n\")\n",
    "\n",
    "proc_path = Path('../data/processed')\n",
    "proc_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save full dataset\n",
    "df_final.to_parquet(proc_path / 'features_engineered.parquet', index=False)\n",
    "\n",
    "# Save splits\n",
    "train.to_parquet(proc_path / 'train.parquet', index=False)\n",
    "val.to_parquet(proc_path / 'val.parquet', index=False)\n",
    "test.to_parquet(proc_path / 'test.parquet', index=False)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'version': '2.0_evidence_based',\n",
    "    'date_created': pd.Timestamp.now().isoformat(),\n",
    "    'total_features': len(feature_columns),\n",
    "    'total_games': len(df_final),\n",
    "    'total_players': df_final['PLAYER_ID'].nunique(),\n",
    "    \n",
    "    'date_range': {\n",
    "        'start': df_final['GAME_DATE'].min().isoformat(),\n",
    "        'end': df_final['GAME_DATE'].max().isoformat()\n",
    "    },\n",
    "    \n",
    "    'feature_names': feature_columns,\n",
    "    \n",
    "    'feature_breakdown': {\n",
    "        'rolling_averages': 9,\n",
    "        'season_context': 6,\n",
    "        'opponent_context': 4,\n",
    "        'team_context': 4,\n",
    "        'game_context': 5,\n",
    "        'shot_tendencies': 4,\n",
    "        'momentum': 6\n",
    "    },\n",
    "    \n",
    "    'evidence_from_eda': {\n",
    "        'high_correlation_features': ['Rolling averages (PTS/REB/AST)', 'Season averages', 'Opponent defense (+9% effect)', 'Home advantage (+1.7%)'],\n",
    "        'low_correlation_features': ['TEAM_PACE (r=0.014, +2.4%)', 'IS_B2B (excluded, paradox +1.7%)'],\n",
    "        'fundamental_challenge': 'FGA (r=0.874) and MIN (r=0.683) unavailable at prediction time',\n",
    "        'opponent_effect': 'Elite D: 12.66 PTS vs Weak D: 13.82 PTS (+9.2%)',\n",
    "        'rest_days_effect': 'Non-linear (4+ days = injury signal, lower scoring)'\n",
    "    },\n",
    "    \n",
    "    'data_quality': {\n",
    "        'leakage_prevention': 'All features use .shift(1) before rolling operations',\n",
    "        'shot_tendencies': 'Season averages only (not per-game)',\n",
    "        'minimum_games': 4,\n",
    "        'source': 'data/processed/gamelogs_combined.parquet (cleaned, deduplicated)'\n",
    "    },\n",
    "    \n",
    "    'train_val_test_split': {\n",
    "        'method': 'Temporal (not random)',\n",
    "        'train': {'end_date': '2023-01-01', 'games': len(train), 'pct': f\"{len(train)/len(df_final)*100:.1f}%\"},\n",
    "        'val': {'start_date': '2023-01-01', 'end_date': '2024-01-01', 'games': len(val), 'pct': f\"{len(val)/len(df_final)*100:.1f}%\"},\n",
    "        'test': {'start_date': '2024-01-01', 'games': len(test), 'pct': f\"{len(test)/len(df_final)*100:.1f}%\"}\n",
    "    },\n",
    "    \n",
    "    'tracking_columns': tracking,\n",
    "    'target_columns': targets,\n",
    "    \n",
    "    'excluded_features': {\n",
    "        'IS_B2B': 'Paradox: +1.7% scoring instead of fatigue (r=+0.009)',\n",
    "        'FGA/MIN': 'Unavailable at prediction time (r=0.874 and r=0.683)',\n",
    "        'Per_game_shot_data': 'Doesnt exist pre-game, using season averages instead'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(proc_path / 'feature_metadata_v2.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"‚úÖ FEATURE ENGINEERING COMPLETE (EVIDENCE-BASED)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  üìä data/processed/features_engineered.parquet ({len(df_final):,} games)\")\n",
    "print(f\"  üìä data/processed/train.parquet ({len(train):,} games)\")\n",
    "print(f\"  üìä data/processed/val.parquet ({len(val):,} games)\")\n",
    "print(f\"  üìä data/processed/test.parquet ({len(test):,} games)\")\n",
    "print(f\"  üìã data/processed/feature_metadata_v2.json\\n\")\n",
    "print(f\"Key improvements from v1.0:\")\n",
    "print(f\"  ‚úÖ Reduced from 81 to {len(feature_columns)} evidence-based features\")\n",
    "print(f\"  ‚úÖ Excluded IS_B2B (no fatigue effect)\")\n",
    "print(f\"  ‚úÖ Shot tendencies as season averages (not per-game)\")\n",
    "print(f\"  ‚úÖ Binned DAYS_REST for non-linear effects\")\n",
    "print(f\"  ‚úÖ Added opponent/team context from processed data\")\n",
    "print(f\"  ‚úÖ Temporal train/val/test split (prevents leakage)\\n\")\n",
    "print(f\"Next step: Notebook 04 for baseline model training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
